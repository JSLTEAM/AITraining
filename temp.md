
---
### 时序数据主流算法深入讲解

#### 1. Transformer时序变体（Informer, Autoformer, TimesNet, Time-LLM）
- **原理**：基于自注意力机制，能建模长序列、多变量间复杂依赖。Informer/Autoformer引入稀疏注意力、分解趋势与周期，TimesNet自动周期提取与多周期卷积，Time-LLM结合大模型能力。
- **优势**：
  - 长序列建模能力强，支持多变量输入
  - 能自动捕捉周期性、趋势性、异常点
  - 并行计算高效，适合大规模数据
  - 适用场景：负荷预测、发电量预测、设备状态监控、气象预测、能耗趋势分析等
- **典型机制**：
  - Informer：ProbSparse Attention，降低计算复杂度
  - Autoformer：趋势/周期分解，提升长期预测能力
  - TimesNet：FFT周期提取+周期卷积，专注周期性时序
  - Time-LLM：Prompt+LLM推理，支持多模态与复杂任务

#### 2. LSTM/GRU
- **原理**：循环神经网络结构，能记忆前后状态，LSTM/GRU通过门控机制缓解长依赖问题。
- **优势**：
  - 适合中短序列、单变量或少变量时序建模
  - 能捕捉短期趋势、局部变化
  - 结构简单，易于实现
  - 适用场景：短期负荷预测、设备寿命预测、异常检测、简单时序分类
- **局限**：
  - 长序列梯度消失/爆炸，周期性建模能力有限
  - 并行计算能力弱，扩展性有限

#### 3. 集成树模型（XGBoost/LightGBM）
- **原理**：基于决策树的集成学习方法，通过Boosting提升预测精度，支持特征重要性分析。
- **优势**：
  - 适合结构化时序特征、异常检测、回归任务
  - 可解释性强，特征选择能力好
  - 对小样本、稀疏特征、异常点鲁棒性高
  - 适用场景：设备状态分类、故障诊断、能耗预测、异常检测、用户行为分析
- **局限**：
  - 对长序列、周期性、复杂依赖建模能力有限
  - 不适合多变量长序列端到端预测

---
### 总结
- Transformer时序变体适合复杂、长序列、多变量、周期性/趋势性强的场景，是当前时序预测主流。
- LSTM/GRU适合中短序列、单变量、局部趋势建模，工程实现简单。
- 集成树模型适合结构化特征、异常检测、回归分类等任务，解释性强。
- 实际应用可根据数据类型、任务需求灵活组合上述算法。
